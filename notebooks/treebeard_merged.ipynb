{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project TreeBeard \n",
    "## An Open Source Solution to Quantifyng Tree Patterns in Forest Land\n",
    "\n",
    "### Objectives\n",
    "\n",
    "The objective of Treebeard is to automate the classification and quantification of land cover from raster mosaic datasets in forested areas. The final product is intended to a be a free open-source GIS plugin  that runs on a python base.  It is intended for users wanting a categorial map of features and open spaces in areas with high densities of trees.  Such a tool would prove valuable to managers in forestry as it would allow them to process information for sizeable tracts of land to identify areas that may need treatment or brush clearing. It could be used to report spatial statistics of stands already undergoind treatment. This would hopefully save time and budget costs by removing the need to manually delineate certain types of spaces by spectral signature, and allowing the user to then run selected computations to report spatial heterogenity characteristics.\n",
    "\n",
    "For this particular study, we will be interested in using our current methods to evaluate the spatial heterogenity in a few sites currently undergoing study in the Lefthand Creek Watershed neard Boulder, Colorado. \n",
    "We aim to use unsupervised clustering methods such as k-means on high resolution aerial photogrpahy of the study site to identify specific tree cluster patterns in the landscape.  After that, we plan to bolster this with canopy height models derived from available LiDAR data at the study site.  This would then allow us to create and designate polygons of the immedaite areas of certain stands  --- which could then allow for quick calcualtions of spatial composition, much faster than processing the mosaic data or manually specifying the areas in a shape file.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background\n",
    "----------\n",
    "\n",
    "### Importance of Spatial Heterogeneity\n",
    "\n",
    "Spatial heterogeneity is a critical factor in assessing the health of an ecosystem. It is commonly utilized to monitor the distribution of tree species, respond to pollutants and diseases among plant populations, and support hydrological studies that assess potential flood paths. Additionally, it plays a crucial role in evaluating and mitigating the risk of wildfires by forest managers.\n",
    "\n",
    "### Application in Landscape Analysis\n",
    "\n",
    "In this project, our focus is on measuring spatial heterogeneity in terms of the distribution of tree groups within the landscape. Specifically, we aim to identify various areas where trees are clustered together in formations ranging from small copses to larger stands. The arrangement and density of these stands are significant as they influence several ecological dynamics, including the patterns of wind flow through the area. When combined with variables such as brush density and canopy overlap, these factors become critical indicators of an area's susceptibility to wildfires.\n",
    "\n",
    "### Impact of Human Activity\n",
    "\n",
    "It is also vital to acknowledge that aerial surveys may capture spatial heterogeneity resulting from human activities, such as land development or resource extraction. These anthropogenic influences often introduce different patterns of spatial composition and configuration compared to those arising from natural processes. A primary goal in forestry management is to restore the land to a condition similar to its pre-European settlement state in North America, believed to represent the most unmodified and stable ecological environment.\n",
    "\n",
    "Study Site Overview\n",
    "-------------------\n",
    "\n",
    "### Left-hand Creek Watershed\n",
    "\n",
    "The study site is located in the Left-hand Creek Watershed. This section of the report will describe the specific area and its forest biome characteristics. The watershed serves as a significant ecological area that supports diverse plant and animal species and plays a crucial role in the local hydrological cycle.\n",
    "\n",
    "The area exists within the Rocky Mountains to the north of Boulder, CO. It featrues moutainaous terrain at a high elevation, with a contiental climate that features large differences in day and night temperature due to high elevation. It is a highly wooded area, with some small rural devleopments found throughout. It is a home to a diverse set of plant and animal life. The area is currently undergoing restoration projects on some of its local streams.\n",
    "\n",
    "![Lefthand Creek](../images/left_hand_creek.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "### Shape files\n",
    "Shape files for the project area of interest were provided by Eric Frederik of the Watershed Center. They indicate sections of land currently under observation by the Watershed Center. These are available as vector polygons in a vareity of machine-readable file formats.\n",
    "\n",
    "### Aerial Data\n",
    "Aerial Data was taken by the Denver Regional Counsel of Governance as part of the Denver Regional Aerial Photography Project (DRAPP) taken every two years.  This is stored on the regional catalog on the [DRCOG website.](https://data.drcog.org/data?page=1&program%5b0%5d=Denver%20Regional%20Aerial%20Photography%20Project&q=&sort=dataVintage)  The resoultion for most of the project is 12 in per pixel.  This data contains four individual spectral bands: red, green, blue, and near infrared -- these are important for calculating  spectral signatures of the areas within the photo.  We are using the 2929 version of the dataset as that is the most recent set freely available to the public. \n",
    "\n",
    "\n",
    "### LiDAR Data\n",
    "LiDar data was also obtained through the DRCOG.  We took our data from the DRCOG LIDAR QL2 INDEX IN CO SP NORTH 2020 set.  This contained mostly point-cloud data that would need to be porcessed into DEM.  Because our area of interest is rural, we must use the QL2 set, which is a qaulity later that will result in a 1 meter cell size in any resulting DEMS.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "### Importing Packages And Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"fd5e5588-be5a-4a3e-8fd6-0d8451139e5c\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"a769e3b9-faa7-4e48-ae10-8e0fb6d5de10\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"a99c0d5500cd48bca29511f0cc066afd\",\"client_comm_id\":\"f4cb7f8184b84a859c7b95d85193c4cf\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"a769e3b9-faa7-4e48-ae10-8e0fb6d5de10\",\"roots\":{\"p1002\":\"fd5e5588-be5a-4a3e-8fd6-0d8451139e5c\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "import contextily as ctx\n",
    "import cv2\n",
    "import earthpy as et\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import hvplot as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrm\n",
    "from ipyleaflet import Map\n",
    "from leafmap import leafmap\n",
    "from localtileserver import get_leaflet_tile_layer, TileClient\n",
    "from rasterio.features import shapes\n",
    "from rasterio.mask import mask\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import requests\n",
    "from samgeo import overlay_images, SamGeo, tms_to_geotiff, get_basemaps\n",
    "from scipy.ndimage import binary_opening, binary_closing\n",
    "import shapely\n",
    "from shapely.geometry import box, Point, shape\n",
    "from shapely.ops import unary_union\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import Image\n",
    "import whitebox\n",
    "import zipfile\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from treebeard.ipynb, commented. \n",
    "\n",
    "# Define the path to the shapefile of the Area of Interest (AOI)\n",
    "shape_file_path = 'assets/areas/immediate_project/Zumwinkel_property.shp'\n",
    "aoi_gdf = gpd.read_file(shape_file_path)\n",
    "\n",
    "# Define directories and filepaths\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME, 'treebeard')\n",
    "\n",
    "# Data Set #1: Denver Regional Aerial Imagery Boundary\n",
    "drapp_url = (\n",
    "    'https://gisdata.drcog.org:8443'\n",
    "    '/geoserver/DRCOGPUB/ows?'\n",
    "    'service=WFS&version=1.0.0&'\n",
    "    'request=GetFeature&'\n",
    "    'typeName=DRCOGPUB:drapp_tile_scheme_2020'\n",
    "    '&outputFormat=SHAPE-ZIP'\n",
    ")\n",
    "drapp_shp_file = os.path.join(data_dir, 'drapp_tile_scheme_2020', 'drapp_tile_scheme_2020.shp')\n",
    "drapp_dir = os.path.join(data_dir, 'drapp_tile_scheme_2020')\n",
    "\n",
    "# Data Set #2: Denver Regional Aerial Imagery Tiles\n",
    "drapp_tiles_dir = os.path.join(data_dir, 'drapp_tiles')\n",
    "os.makedirs(drapp_tiles_dir, exist_ok=True)\n",
    "\n",
    "# Download the DRAPP shapefile if it does not exist\n",
    "if not os.path.exists(drapp_shp_file):\n",
    "    drapp_resp = requests.get(drapp_url)\n",
    "else:\n",
    "    print(f'Data {drapp_shp_file.split(\"/\")[-1]} already downloaded.')\n",
    "\n",
    "# Function to extract a zip file to a target directory\n",
    "def extract_zip(target_dir, zip_filename, resp):\n",
    "    zip_path = os.path.join(data_dir, zip_filename)\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        f.write(resp.content)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(target_dir)\n",
    "\n",
    "# Extract the DRAPP shapefile if it is not already extracted\n",
    "drapp_dir = os.path.join(data_dir, 'drapp_tile_scheme_2020')\n",
    "if not os.path.exists(drapp_shp_file):\n",
    "    extract_zip(data_dir, 'drapp_tile_scheme_2020.zip', drapp_resp)\n",
    "else:\n",
    "    print(f'Data {drapp_shp_file.split(\"/\")[-1]} already extracted.')\n",
    "\n",
    "# Check the Coordinate Reference System (CRS) of the AOI GeoDataFrame\n",
    "aoi_gdf.crs\n",
    "\n",
    "# Create a bounding box around the AOI\n",
    "bbox_aoi_gdf = gpd.GeoDataFrame(geometry=aoi_gdf.bounds.apply(lambda row: box(row['minx'], row['miny'], row['maxx'], row['maxy']), axis=1))\n",
    "bbox_aoi_gdf.crs = aoi_gdf.crs\n",
    "\n",
    "# Read the DRAPP shapefile and reproject to match the AOI CRS\n",
    "drapp_gdf = gpd.read_file(drapp_shp_file)\n",
    "drapp_gdf = drapp_gdf.to_crs(aoi_gdf.crs) # EPSG:6428 -> EPSG:4326\n",
    "\n",
    "# Spatial join between DRAPP tiles and the AOI\n",
    "drapp_aoi_gdf = gpd.sjoin(drapp_gdf, aoi_gdf, how='inner', predicate='intersects')\n",
    "\n",
    "# Plot the AOI, bounding box, and DRAPP tiles\n",
    "aoi_plot = aoi_gdf.hvplot(\n",
    "        geo=True, tiles='OSM', alpha=1, \n",
    "        height=800, width=800, color='red',\n",
    "        label='Area of Interest'\n",
    "    )\n",
    "aoi_bound_plot = bbox_aoi_gdf.hvplot(\n",
    "        geo=True, tiles='OSM', alpha=0.7, \n",
    "        color='blue',\n",
    "        label='AOI Bounding Box'\n",
    "    )\n",
    "drapp_plot = drapp_aoi_gdf.hvplot(\n",
    "        geo=True, tiles='OSM', \n",
    "        alpha=0.3, color='blue',\n",
    "        hover_cols=['tile', 'photo_date'],\n",
    "        title='Area of Interest in DRAPP Tile N4W351'\n",
    "    )\n",
    "composite_plot = aoi_bound_plot * drapp_plot * aoi_plot\n",
    "\n",
    "# Save and display the plots\n",
    "Image(\"images/aoi_plot.png\")\n",
    "Image(\"images/composite_plot.png\")\n",
    "\n",
    "# Generate URLs for downloading DRAPP tiles\n",
    "tile_base_url = 'https://drapparchive.s3.amazonaws.com/2020/'\n",
    "tile_urls = [f'{tile_base_url}{tile}.tif' for tile in drapp_aoi_gdf['tile'].unique()]\n",
    "\n",
    "# Create directory for DRAPP tiles\n",
    "drapp_tiles_dir = os.path.join(data_dir, 'drapp_tiles')\n",
    "os.makedirs(drapp_tiles_dir, exist_ok=True)\n",
    "\n",
    "# Function to download files from URLs\n",
    "def download_files(urls):\n",
    "    paths = []\n",
    "    for url in urls:\n",
    "        filename = os.path.basename(url)\n",
    "        path = os.path.join(drapp_tiles_dir, filename)\n",
    "        paths.append(path)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Downloading {url}...\")\n",
    "            resp = requests.get(url)\n",
    "            with open(path, 'wb') as f:\n",
    "                f.write(resp.content)\n",
    "        else:\n",
    "            print(f\"File {filename} already downloaded.\")\n",
    "    return paths\n",
    "\n",
    "# Download DRAPP tile files\n",
    "tile_paths = download_files(tile_urls)\n",
    "\n",
    "# Extract photo date and tile name for the first tile\n",
    "photo_date = pd.to_datetime(\n",
    "        drapp_aoi_gdf['photo_date']\n",
    "    ).dt.date.unique()[0].strftime('%Y-%m-%d')\n",
    "tile_name = drapp_aoi_gdf['tile'].unique()[0]\n",
    "\n",
    "# Open and merge the DRAPP tiles to create a mosaic\n",
    "src_files_to_mosaic = [rasterio.open(path) for path in tile_paths]\n",
    "mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "red = mosaic[0]\n",
    "green = mosaic[1]\n",
    "blue = mosaic[2]\n",
    "nir = mosaic[3]\n",
    "rgb = np.dstack((red, green, blue))\n",
    "plt.imshow(rgb)\n",
    "plt.title(f'RGB Image: DRAPP Tile {tile_name} ({photo_date})')\n",
    "plt.savefig('images/N4W351_rgb_image.png')\n",
    "plt.show()\n",
    "\n",
    "# Crop the mosaic using the AOI bounding box\n",
    "with rasterio.open(tile_paths[0]) as src:\n",
    "    # Ensure CRS match between raster and GeoDataFrame\n",
    "    if bbox_aoi_gdf.crs != src.crs:\n",
    "        bbox_aoi_gdf = bbox_aoi_gdf.to_crs(src.crs)\n",
    "\n",
    "    # Create a mask for cropping\n",
    "    geom = [bbox_aoi_gdf.geometry.unary_union]  # Combine all geometries in the GeoDataFrame\n",
    "    out_image, out_transform = mask(src, geom, crop=True)\n",
    "\n",
    "    # Update the metadata for the cropped raster\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform\n",
    "    })\n",
    "\n",
    "# Save the cropped raster to a file\n",
    "cropped_file = \"scratch/cropped_N4W351.tif\"\n",
    "with rasterio.open(cropped_file, \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "\n",
    "# Plot the cropped RGB image\n",
    "with rasterio.open(cropped_file) as src:\n",
    "    red = src.read(1)\n",
    "    green = src.read(2)\n",
    "    blue = src.read(3)\n",
    "    rgb = np.dstack((red, green, blue))\n",
    "    plt.imshow(rgb)\n",
    "    plt.title(f'Cropped RGB Image: DRAPP Tile {tile_name} ({photo_date})')\n",
    "    plt.savefig('images/cropped_N4W351_rgb_image.png')\n",
    "    plt.show()\n",
    "\n",
    "# Load the cropped GeoTIFF file for further processing\n",
    "geotiff = \"scratch/cropped_N4W351.tif\"\n",
    "with rasterio.open(geotiff) as src:\n",
    "    bands = [src.read(i) for i in range(1, 5)]\n",
    "    image_data = np.dstack(bands)\n",
    "\n",
    "# Prepare the data for clustering\n",
    "pixels = image_data.reshape((-1, 4))  # Flatten the image data for clustering\n",
    "\n",
    "# Perform K-means clustering for 2 to 5 clusters\n",
    "predictions = {}\n",
    "for k in range(2, 6): \n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10)\n",
    "    kmeans.fit(pixels)\n",
    "    labels = kmeans.labels_\n",
    "    segmented_image = labels.reshape(image_data.shape[0], image_data.shape[1])\n",
    "    predictions[k] = segmented_image\n",
    "\n",
    "# Plot the clustering results\n",
    "f, axes = plt.subplots(2, 2, figsize=(15, 15))  # Adjust subplot layout\n",
    "for ax_i, (k, prediction) in enumerate(predictions.items()):\n",
    "    if ax_i >= 6:\n",
    "        continue\n",
    "    ax = axes.flatten()[ax_i]\n",
    "    im = ax.imshow(prediction, cmap=\"terrain\", interpolation='none')\n",
    "    ax.set_title(\"Number of clusters: \" + str(k))\n",
    "    ax.axis('off')  # Hide axis ticks\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Open the GeoTIFF file\n",
    "image = rasterio.open(geotiff)\n",
    "\n",
    "# Read the red, green, blue, and NIR bands from the image\n",
    "red = image.read(1).astype(float)\n",
    "green = image.read(2).astype(float)\n",
    "blue = image.read(3).astype(float)\n",
    "nir = image.read(4).astype(float)\n",
    "\n",
    "# Stack the bands into a single array\n",
    "bands = np.dstack((red, green, blue, nir))\n",
    "\n",
    "# Get the number of bands in the image\n",
    "nbands = image.read().shape[0]\n",
    "\n",
    "# Close the image file\n",
    "image.close()\n",
    "\n",
    "# Calculate the NDVI (Normalized Difference Vegetation Index)\n",
    "ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "# Replace NaN values in the NDVI with 0\n",
    "ndvi[np.isnan(ndvi)] = 0\n",
    "\n",
    "# Create a mask for open spaces where NDVI is greater than or equal to 0.1\n",
    "open_spaces = ndvi >= 0.1\n",
    "\n",
    "# Display the open spaces mask\n",
    "show(open_spaces, cmap='Greys')\n",
    "\n",
    "# Function to save a NumPy array as a GeoTIFF\n",
    "def array_to_image(\n",
    "    array, output, source=None, dtype=None, compress=\"deflate\", **kwargs\n",
    "):\n",
    "    \"\"\"Save a NumPy array as a GeoTIFF using the projection information from an existing GeoTIFF file.\n",
    "\n",
    "    Args:\n",
    "        array (np.ndarray): The NumPy array to be saved as a GeoTIFF.\n",
    "        output (str): The path to the output image.\n",
    "        source (str, optional): The path to an existing GeoTIFF file with map projection information. Defaults to None.\n",
    "        dtype (np.dtype, optional): The data type of the output array. Defaults to None.\n",
    "        compress (str, optional): The compression method. Can be one of the following: \"deflate\", \"lzw\", \"packbits\", \"jpeg\". Defaults to \"deflate\".\n",
    "    \"\"\"\n",
    "    \n",
    "    from PIL import Image\n",
    "\n",
    "    if isinstance(array, str) and os.path.exists(array):\n",
    "        array = cv2.imread(array)\n",
    "        array = cv2.cvtColor(array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if output.endswith(\".tif\") and source is not None:\n",
    "        with rasterio.open(source) as src:\n",
    "            crs = src.crs\n",
    "            transform = src.transform\n",
    "            if compress is None:\n",
    "                compress = src.compression\n",
    "\n",
    "        # Determine the minimum and maximum values in the array\n",
    "        min_value = np.min(array)\n",
    "        max_value = np.max(array)\n",
    "\n",
    "        if dtype is None:\n",
    "            # Determine the best dtype for the array\n",
    "            if min_value >= 0 and max_value <= 1:\n",
    "                dtype = np.float32\n",
    "            elif min_value >= 0 and max_value <= 255:\n",
    "                dtype = np.uint8\n",
    "            elif min_value >= -128 and max_value <= 127:\n",
    "                dtype = np.int8\n",
    "            elif min_value >= 0 and max_value <= 65535:\n",
    "                dtype = np.uint16\n",
    "            elif min_value >= -32768 and max_value <= 32767:\n",
    "                dtype = np.int16\n",
    "            else:\n",
    "                dtype = np.float64\n",
    "\n",
    "        # Convert the array to the best dtype\n",
    "        array = array.astype(dtype)\n",
    "\n",
    "        # Define the GeoTIFF metadata\n",
    "        if array.ndim == 2:\n",
    "            metadata = {\n",
    "                \"driver\": \"GTiff\",\n",
    "                \"height\": array.shape[0],\n",
    "                \"width\": array.shape[1],\n",
    "                \"count\": 1,\n",
    "                \"dtype\": array.dtype,\n",
    "                \"crs\": crs,\n",
    "                \"transform\": transform,\n",
    "            }\n",
    "        elif array.ndim == 3:\n",
    "            metadata = {\n",
    "                \"driver\": \"GTiff\",\n",
    "                \"height\": array.shape[0],\n",
    "                \"width\": array.shape[1],\n",
    "                \"count\": array.shape[2],\n",
    "                \"dtype\": array.dtype,\n",
    "                \"crs\": crs,\n",
    "                \"transform\": transform,\n",
    "            }\n",
    "\n",
    "        if compress is not None:\n",
    "            metadata[\"compress\"] = compress\n",
    "        else:\n",
    "            raise ValueError(\"Array must be 2D or 3D.\")\n",
    "\n",
    "        # Create a new GeoTIFF file and write the array to it\n",
    "        with rasterio.open(output, \"w\", **metadata) as dst:\n",
    "            if array.ndim == 2:\n",
    "                dst.write(array, 1)\n",
    "            elif array.ndim == 3:\n",
    "                for i in range(array.shape[2]):\n",
    "                    dst.write(array[:, :, i], i + 1)\n",
    "\n",
    "    else:\n",
    "        img = Image.fromarray(array)\n",
    "        img.save(output, **kwargs)\n",
    "\n",
    "# Save the open spaces mask as a GeoTIFF file\n",
    "mask_output = \"ndvi-open-spaces.tif\"\n",
    "array_to_image(open_spaces, mask_output, source=geotiff)\n",
    "\n",
    "# Perform K-means clustering with 2 clusters on the image pixels\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(pixels)\n",
    "\n",
    "# Get the cluster labels for each pixel\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Reshape the cluster labels to the original image shape\n",
    "clustered_image = cluster_labels.reshape(image_data.shape[:2])\n",
    "\n",
    "# Create a binary mask for a specific cluster (e.g., cluster 0)\n",
    "binary_mask = (clustered_image == 0).astype(np.uint8) * 255\n",
    "binary_mask = binary_mask == 0\n",
    "\n",
    "# Display the binary mask\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(binary_mask, cmap='Greys')\n",
    "plt.title('Binary Mask from K-Means Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Save the binary mask as a GeoTIFF file\n",
    "array_to_image(binary_mask, 'kmeans-open-spaces.tif', source=geotiff)\n",
    "\n",
    "# Define file paths for the NDVI and K-means masks\n",
    "ndvi_mask = 'ndvi-open-spaces.tif'\n",
    "kmeans_mask = 'kmeans-open-spaces.tif'\n",
    "\n",
    "# Function to convert a GeoTIFF to a GeoDataFrame\n",
    "def geotiff_to_gdf(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        mask = src.read(1).astype('uint8')\n",
    "        mask_transform = src.transform\n",
    "        geometries = list(shapes(mask, transform=mask_transform))\n",
    "        shapes_list = [{'properties': {'raster_val': v}, 'geometry': shape(geom)}\n",
    "                        for geom, v in geometries if v == 0]\n",
    "        gdf = gpd.GeoDataFrame.from_features(shapes_list)\n",
    "        gdf.crs = src.crs\n",
    "    return gdf\n",
    "\n",
    "# Function to save a GeoDataFrame as a shapefile\n",
    "def gdf_to_shp(gdf, out_path):\n",
    "    gdf.to_file(out_path)\n",
    "\n",
    "# Function to calculate the area of each polygon in a GeoDataFrame\n",
    "def calculate_area(gdf):\n",
    "    gdf['area_feet'] = gdf.area\n",
    "    gdf['area_acres'] = gdf['area_feet'] / 43560\n",
    "    return gdf['area_acres']\n",
    "\n",
    "# List of mask file paths to process\n",
    "files = [ndvi_mask, kmeans_mask]\n",
    "results = []\n",
    "\n",
    "# Process each mask file\n",
    "for file in files:\n",
    "    filename = file\n",
    "    gdf = geotiff_to_gdf(file)    \n",
    "    gdf['area_acres'] = calculate_area(gdf)\n",
    "    results.append(gdf)\n",
    "\n",
    "# Function to plot the size categories of polygons in a GeoDataFrame\n",
    "def bin_plot(gdf, bins, labels, title):\n",
    "    gdf['size_category'] = pd.cut(gdf['area_acres'], bins=bins, labels=labels, right=False)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    plot = gdf.plot(column='size_category', ax=ax, legend=True, categorical=True, legend_kwds={'title': 'Size Category'})\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    filename = title.split('.')[0]\n",
    "    plt.savefig(f'{filename}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the size categories for each processed mask\n",
    "for i, result in enumerate(results):\n",
    "    bins = [0, 1/8, 1/4, 1/2, 1]\n",
    "    labels = ['1/8 acre', '1/4 acre', '1/2 acre', '1+ acres']\n",
    "    title = files[i]\n",
    "    bin_plot(result, bins, labels, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_lidar.ipynb code, commented\n",
    "\n",
    "import os\n",
    "import earthpy as et\n",
    "import geopandas as gpd\n",
    "import hvplot as hv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrm\n",
    "from scipy.ndimage import binary_opening, binary_closing\n",
    "import shapely\n",
    "from shapely.geometry import shape\n",
    "import whitebox\n",
    "import zipfile\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Import the LIDAR index grid and set up directories\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME)\n",
    "project_dir = os.path.join(data_dir, \"treebeard\")\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "las_index_path = os.path.join(\n",
    "    data_dir,\n",
    "    'earthpy-downloads',\n",
    "    'lidar_index_cspn_q2',\n",
    "    'lidar_index_cspn_q2.shp'\n",
    ")\n",
    "\n",
    "# Download LIDAR index tiles if not already present\n",
    "if not os.path.exists(las_index_path):\n",
    "    las_index_url = ('https://gisdata.drcog.org:8443/geoserver/DRCOGPUB/'\n",
    "             'ows?service=WFS&version=1.0.0&request=GetFeature&'\n",
    "             'typeName=DRCOGPUB:lidar_index_cspn_q2&outputFormat=SHAPE-ZIP')\n",
    "\n",
    "    las_index_shp = et.data.get_data(url=las_index_url)\n",
    "\n",
    "# Read the LIDAR index shapefile and set its CRS\n",
    "las_index_gdf = (\n",
    "    gpd.read_file(las_index_path).set_index('tile')\n",
    "#    .loc[['N3W345']]  # Uncomment and specify tiles if needed\n",
    ")\n",
    "\n",
    "las_index_gdf = las_index_gdf.to_crs('EPSG:4269')\n",
    "crs = las_index_gdf.crs\n",
    "\n",
    "# Plot the LIDAR index grid using hvplot\n",
    "las_index_plot = las_index_gdf.hvplot(\n",
    "    tiles='OSM',\n",
    "    crs=las_index_gdf.crs,\n",
    "    geo=True,\n",
    "    line_color='black',\n",
    "    line_width=2,\n",
    "    fill_alpha=0\n",
    ")\n",
    "las_index_plot\n",
    "\n",
    "# Open project areas shapefile and plot\n",
    "proj_zip_path = '../assets/project_areas_merged.zip'\n",
    "\n",
    "with zipfile.ZipFile(proj_zip_path, 'r') as zip_ref:\n",
    "    temp_dir = '/tmp/extracted_shapefile'  # You can specify any temporary directory\n",
    "    zip_ref.extractall(temp_dir)\n",
    "\n",
    "extracted_shapefile_path = temp_dir + '/'\n",
    "\n",
    "proj_area_gdf = gpd.read_file(extracted_shapefile_path)\n",
    "\n",
    "# Convert project area CRS to EPSG:4326\n",
    "proj_area_gdf = proj_area_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Plot the project areas using hvplot\n",
    "proj_area_plot = proj_area_gdf.hvplot(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    aspect='equal',\n",
    "    tiles='EsriImagery',\n",
    "    geo=True,\n",
    "    line_color='blue',\n",
    "    line_width=2,\n",
    "    fill_alpha=0\n",
    ")\n",
    "\n",
    "proj_area_plot\n",
    "\n",
    "# Identify the tiles that intersect each project area using spatial join\n",
    "select_tiles_gdf = gpd.sjoin(las_index_gdf, proj_area_gdf, how='inner', predicate='intersects')\n",
    "\n",
    "select_tiles_gdf.reset_index(drop=False)\n",
    "select_tiles_gdf.hvplot(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    aspect='equal',\n",
    "    tiles='EsriImagery',\n",
    "    geo=True,\n",
    "    line_color='blue',\n",
    "    line_width=2,\n",
    "    fill_alpha=0\n",
    ")\n",
    "\n",
    "# Reset index for the selected tiles\n",
    "select_tiles_gdf = select_tiles_gdf.reset_index(drop=False)\n",
    "\n",
    "# Generate list of all tiles per project area\n",
    "tiles_by_area = select_tiles_gdf.groupby('Proj_ID')['tile'].apply(list).reset_index()\n",
    "tiles_by_area\n",
    "\n",
    "# Function to process LAS files to canopy using Whitebox\n",
    "def convert_las_to_tif(input_las, output_tif, return_type):\n",
    "    \"\"\"\n",
    "    Converts a LAS file to a GeoTIFF using WhiteboxTools, based on the specified return type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_las : str\n",
    "        Path to the input LAS file.\n",
    "    output_tif : str\n",
    "        Path to save the output GeoTIFF file.\n",
    "    return_type : str\n",
    "        Type of returns to process. Must be either 'first' for first returns or 'ground' for ground returns.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `return_type` is not 'first' or 'ground'.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function uses WhiteboxTools' `lidar_idw_interpolation` method to perform the conversion.\n",
    "    The interpolation method used is Inverse Distance Weighting (IDW) with a resolution of 1.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> convert_las_to_tif_whitebox('input.las', 'output_first_returns.tif', 'first')\n",
    "    >>> convert_las_to_tif_whitebox('input.las', 'output_ground_returns.tif', 'ground')\n",
    "    \"\"\"\n",
    "    wbt = whitebox.WhiteboxTools()\n",
    "    \n",
    "    if return_type == \"first\":\n",
    "        wbt.lidar_idw_interpolation(\n",
    "            i=input_las,\n",
    "            output=output_tif,\n",
    "            parameter=\"return_num\",\n",
    "            returns=1,\n",
    "            resolution=1  # Adjust as needed\n",
    "        )\n",
    "    elif return_type == \"ground\":\n",
    "        wbt.lidar_idw_interpolation(\n",
    "            i=input_las,\n",
    "            output=output_tif,\n",
    "            parameter=\"classification\",\n",
    "            classification=2,\n",
    "            resolution=1  # Adjust as needed\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid return_type. Use 'first' or 'ground'.\")\n",
    "\n",
    "# Process tiles for each project area\n",
    "# Generate a dictionary of canopy TIFs for each project area\n",
    "las_root_url = 'https://lidararchive.s3.amazonaws.com/2020_CSPN_Q2/'\n",
    "canopy_dict = {}\n",
    "for index, row in tiles_by_area.iterrows():\n",
    "    tiles = row['tile']\n",
    "    proj_area_name = row['Proj_ID']\n",
    "    sel_proj_area_gdf = proj_area_gdf[proj_area_gdf['Proj_ID'] == proj_area_name]\n",
    "    # Download all tiles for project area, process, and clip/merge\n",
    "    tile_agg = []\n",
    "    print(\"Processing LIDAR for \" + proj_area_name)\n",
    "    for tile in tiles:\n",
    "        file_name = tile + \".las\"\n",
    "        print(\"Processing LIDAR tile \" + tile)\n",
    "        tile_path = os.path.join(\n",
    "            data_dir,\n",
    "            'earthpy-downloads',\n",
    "            file_name\n",
    "        )\n",
    "        download_url = las_root_url + tile + \".las\"\n",
    "        if not os.path.exists(tile_path):\n",
    "            et.data.get_data(url=download_url)\n",
    "        # PDAL is required for this step, see readme for install instructions\n",
    "\n",
    "        # Output path for first returns DEM\n",
    "        output_fr_tif = os.path.join(\n",
    "            project_dir,\n",
    "            tile +'_fr.tif'\n",
    "        )\n",
    "        if not os.path.exists(output_fr_tif):\n",
    "            convert_las_to_tif(tile_path, output_fr_tif, \"first\")\n",
    "        \n",
    "        # Output path for ground DEM\n",
    "        output_gr_tif = os.path.join(\n",
    "            project_dir,\n",
    "            tile +'_gr.tif'\n",
    "        )\n",
    "        if not os.path.exists(output_gr_tif):\n",
    "            convert_las_to_tif(tile_path, output_gr_tif, \"ground\")\n",
    "        \n",
    "        # Process ground and first return data to canopy height\n",
    "        fr_dem = rxr.open_rasterio(output_fr_tif)\n",
    "        fr_dem = fr_dem.rio.reproject(\"EPSG:4326\")\n",
    "\n",
    "        gr_dem = rxr.open_rasterio(output_gr_tif)\n",
    "        gr_dem = gr_dem.rio.reproject(\"EPSG:4326\")\n",
    "        gr_dem = gr_dem.rio.reproject_match(fr_dem)\n",
    "\n",
    "        # Calculate canopy height by subtracting ground DEM from first returns DEM\n",
    "        canopy_dem = fr_dem - gr_dem\n",
    "\n",
    "        # Set all values greater than 1 (canopy) to 1 and all values less than 1 (no canopy) to 0\n",
    "        canopy_dem.values[canopy_dem < 1] = 0\n",
    "        canopy_dem.values[canopy_dem > 1] = 1\n",
    "        canopy_dem.name = tile + \"_Canopy\"\n",
    "        canopy_dem = canopy_dem.round()\n",
    "        tile_agg.append(canopy_dem)\n",
    "    print(\"Merging LIDAR tiles for \" + proj_area_name)\n",
    "    # Merge all tiles that intersect with the project area and clip to project area\n",
    "    canopy_merged = rxrm.merge_arrays(tile_agg).rio.clip(sel_proj_area_gdf.geometry)\n",
    "    canopy_dict[proj_area_name] = canopy_merged\n",
    "\n",
    "\n",
    "\n",
    "# Export Zumwinkel canopy tif to repo\n",
    "test = canopy_dict['Zumwinkel']\n",
    "\n",
    "zumwinkel_path = \"../notebooks/zumwinkel_canopy.tif\"\n",
    "\n",
    "# Check if the output path exists before exporting\n",
    "if not os.path.exists(zumwinkel_path):\n",
    "    test.rio.to_raster(zumwinkel_path, overwrite=True) \n",
    "\n",
    "# Plot Zumwinkel canopy tif\n",
    "zumwinkel_path = \"../notebooks/zumwinkel_canopy.tif\"\n",
    "\n",
    "# Load and reproject the Zumwinkel canopy raster\n",
    "zumwinkel_lidar = rxr.open_rasterio(zumwinkel_path).rio.reproject(\"EPSG:4326\")\n",
    "zumwinkel_lidar.hvplot(\n",
    "    height=600,\n",
    "    width=600,\n",
    "    geo=True,\n",
    "    aspect='equal',\n",
    "    kind='image',\n",
    "    tiles='EsriImagery',\n",
    "    alpha=0.5,\n",
    "    title=\"LIDAR Canopy Example\",\n",
    "    clabel='Height in feet',\n",
    "    crs=canopy_dem.rio.crs  # CRS from canopy_dem\n",
    ")\n",
    "\n",
    "# Clean up \"noise\" in raster\n",
    "\n",
    "# Function to apply morphological operations on a rioxarray DataArray\n",
    "def clean_raster_rioxarray(raster_xarray, operation='opening', structure_size=3):\n",
    "    # Extract the numpy array from the xarray DataArray\n",
    "    raster_data = raster_xarray.values\n",
    "\n",
    "    # Ensure the raster_data is 2D (in case it's a single-band raster with an extra dimension)\n",
    "    if raster_data.ndim == 3 and raster_data.shape[0] == 1:\n",
    "        raster_data = raster_data[0, :, :]\n",
    "    \n",
    "    # Convert to binary (tree canopy is represented by 1, no canopy by 0)\n",
    "    binary_raster = raster_data == 1\n",
    "\n",
    "    # Define the structure for the morphological operation\n",
    "    structure = np.ones((structure_size, structure_size), dtype=int)\n",
    "\n",
    "    # Apply the chosen morphological operation\n",
    "    if operation == 'opening':\n",
    "        cleaned_raster = binary_opening(binary_raster, structure=structure)\n",
    "    elif operation == 'closing':\n",
    "        cleaned_raster = binary_closing(binary_raster, structure=structure)\n",
    "    else:\n",
    "        raise ValueError(\"Operation must be 'opening' or 'closing'\")\n",
    "\n",
    "    # Convert back to the original values (1 for canopy, 0 for no canopy)\n",
    "    raster_data_cleaned = np.where(cleaned_raster, 1, 0)\n",
    "\n",
    "    # Add back the extra dimension if the original data had it\n",
    "    if raster_xarray.values.ndim == 3:\n",
    "        raster_data_cleaned = np.expand_dims(raster_data_cleaned, axis=0)\n",
    "\n",
    "    # Create a new xarray DataArray with the cleaned data, copying metadata from the original\n",
    "    cleaned_raster_xarray = raster_xarray.copy(data=raster_data_cleaned)\n",
    "\n",
    "    return cleaned_raster_xarray\n",
    "\n",
    "# Choose morphological operation and structure size\n",
    "operation = 'opening'\n",
    "structure_size = 3\n",
    "\n",
    "# Apply the cleaning function to the raster\n",
    "zumwinkel_lidar_cleaned = clean_raster_rioxarray(zumwinkel_lidar, operation, structure_size)\n",
    "\n",
    "# Plot the cleaned raster\n",
    "lidar_plot = zumwinkel_lidar_cleaned.hvplot(\n",
    "    height=600,\n",
    "    width=600,\n",
    "    geo=True,\n",
    "    aspect='equal',\n",
    "    kind='image',\n",
    "    tiles='EsriImagery',\n",
    "    alpha=0.5,\n",
    "    title=\"LIDAR Canopy Example\",\n",
    "    clabel='Height in feet',\n",
    "    crs=canopy_dem.rio.crs\n",
    ")\n",
    "\n",
    "# Create a vector binary mask for canopy\n",
    "\n",
    "# Export cleaned Zumwinkel canopy tif to repo\n",
    "zumwinkel_path = \"../notebooks/zumwinkel_clean_canopy.tif\"\n",
    "zumwinkel_lidar_cleaned = zumwinkel_lidar_cleaned.where(zumwinkel_lidar_cleaned != 1.7976931348623157e+308, np.nan)\n",
    "zumwinkel_lidar_cleaned.rio.to_raster(zumwinkel_path, overwrite=True)\n",
    "\n",
    "# Load the TIF file using rioxarray\n",
    "binary_mask = zumwinkel_lidar_cleaned.squeeze()  # Assuming the data is in the first band\n",
    "\n",
    "# Create a mask where cell values are 1\n",
    "mask = binary_mask == 1\n",
    "\n",
    "# Get the affine transform from the raster data\n",
    "transform = binary_mask.rio.transform()\n",
    "\n",
    "# Extract shapes (polygons) from the binary mask\n",
    "shapes = rasterio.features.shapes(mask.astype(np.int16).values, transform=transform)\n",
    "polygons = [shape(geom) for geom, value in shapes if value == 1]\n",
    "\n",
    "# Create a GeoDataFrame from the polygons\n",
    "canopy_gdf = gpd.GeoDataFrame({'geometry': polygons})\n",
    "\n",
    "# Prep data for vector processing. Make sure CRS is set to coordinate system with correct units.\n",
    "\n",
    "# Get CRS from raster\n",
    "crs = zumwinkel_lidar_cleaned.rio.crs\n",
    "\n",
    "# Set CRS for GeoDataFrame if not already set\n",
    "if canopy_gdf.crs is None:\n",
    "    canopy_gdf = canopy_gdf.set_crs(zumwinkel_lidar_cleaned.rio.crs)\n",
    "\n",
    "# Define EPSG:6430 CRS\n",
    "epsg_6430 = '6430'\n",
    "\n",
    "# Reproject to EPSG:6430\n",
    "canopy_gdf = canopy_gdf.to_crs(epsg=epsg_6430)\n",
    "\n",
    "# Filter project area GeoDataFrame for Zumwinkel and reproject\n",
    "zumwinkel_boundary = proj_area_gdf[proj_area_gdf['Proj_ID'] == \"Zumwinkel\"]\n",
    "zumwinkel_boundary = zumwinkel_boundary.to_crs(\"EPSG:6430\")\n",
    "\n",
    "# Method to process canopy gaps\n",
    "\n",
    "def process_canopy_areas(canopy_gdf, study_area, buffer_distance=5):\n",
    "    \"\"\"\n",
    "    Processes canopy areas by buffering, dissolving, clipping, and exploding the geometries.\n",
    "    Adds acreage and size category columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    canopy_gdf : gpd.GeoDataFrame\n",
    "        GeoDataFrame representing canopy areas.\n",
    "    study_area : gpd.GeoDataFrame\n",
    "        GeoDataFrame representing the boundary within which to clip the canopy areas.\n",
    "    buffer_distance : float, optional\n",
    "        The distance to buffer the canopy geometries. Default is 5 units.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    exploded_gap_gdf : gpd.GeoDataFrame\n",
    "        GeoDataFrame with exploded geometries representing non-tree canopy areas, including acreage and size category.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure input GeoDataFrames have CRS\n",
    "    if canopy_gdf.crs is None or study_area.crs is None:\n",
    "        raise ValueError(\"Input GeoDataFrames must have a CRS defined.\")\n",
    "\n",
    "    # Buffer the canopy geometries\n",
    "    buffered_canopy = canopy_gdf.geometry.buffer(buffer_distance)\n",
    "\n",
    "    # Create a new GeoDataFrame with the buffered geometries\n",
    "    buffer_gdf = gpd.GeoDataFrame(geometry=buffered_canopy, crs=canopy_gdf.crs)\n",
    "\n",
    "    # Dissolve the buffered geometries into a single MultiPolygon\n",
    "    dissolved_canopy = unary_union(buffer_gdf.geometry)\n",
    "\n",
    "    # Convert the dissolved canopy back to a GeoDataFrame\n",
    "    dissolved_canopy_gdf = gpd.GeoDataFrame(geometry=[dissolved_canopy], crs=canopy_gdf.crs)\n",
    "\n",
    "    # Clip the dissolved canopy with the study area\n",
    "    clipped_buffer = gpd.overlay(dissolved_canopy_gdf, study_area, how='intersection')\n",
    "\n",
    "    # Calculate the difference between the study area and the clipped buffer\n",
    "    non_tree_canopy_gdf = gpd.overlay(study_area, clipped_buffer, how='difference')\n",
    "\n",
    "    # Explode multipart polygon to prepare for area calculations\n",
    "    exploded_gap_gdf = non_tree_canopy_gdf.explode(index_parts=True)\n",
    "\n",
    "    # Reset the index to have a clean DataFrame\n",
    "    exploded_gap_gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Calculate the area in acres (1 acre = 43,560 square feet)\n",
    "    exploded_gap_gdf['Acreage'] = exploded_gap_gdf.geometry.area / 43560\n",
    "\n",
    "    # Define a function to categorize the gap size\n",
    "    def categorize_gap_size(acres):\n",
    "        if acres < 1/8:\n",
    "            return '< 1/8 acre'\n",
    "        elif 1/8 <= acres < 1/4:\n",
    "            return '1/8 - 1/4 acre'\n",
    "        elif 1/4 <= acres < 1/2:\n",
    "            return '1/4 - 1/2 acre'\n",
    "        elif 1/2 <= acres < 1:\n",
    "            return '1/2 - 1 acre'\n",
    "        else:\n",
    "            return '> 1 acre'\n",
    "\n",
    "    # Apply the categorization function to the Acreage column\n",
    "    exploded_gap_gdf['Gap_Size_Category'] = exploded_gap_gdf['Acreage'].apply(categorize_gap_size)\n",
    "\n",
    "    return exploded_gap_gdf\n",
    "\n",
    "# Process the canopy gaps for the Zumwinkel area\n",
    "canopy_gaps_calced = process_canopy_areas(canopy_gdf, zumwinkel_boundary, buffer_distance=5)\n",
    "\n",
    "# Save the processed canopy gaps to a shapefile\n",
    "canopy_gaps_calced.to_file('canopy_gaps_calced.shp')\n",
    "\n",
    "# Reproject the canopy gaps back to EPSG:4326 for plotting\n",
    "canopy_gaps_calced = canopy_gaps_calced.to_crs(\"EPSG:4326\")\n",
    "canopy_gaps_calced.hvplot(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    aspect='equal',\n",
    "    geo=True,\n",
    "    line_color='blue',\n",
    "    line_width=2,\n",
    "    width=600,\n",
    "    height=600,\n",
    "    tiles='EsriImagery',\n",
    "    title=\"Processed Canopy Gaps from LIDAR\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
